{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burst Detection - R library wrapped using rpy2\n",
    "To run properly, this notebook requires a working install of R with special packages **pracma, sjemea, and e1071**.\n",
    "To test it out, you can use my custom python install located on the network: */allen/aibs/mat/Peter/renv/*, which can be started using **source /allen/aibs/mat/Peter/renv/bin/activate**\n",
    "\n",
    "This script has been modified from it's original version by Marcus Blackburn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Readme for the R-code used in this notebook:**\n",
    "\n",
    "**Burst-analysis**\n",
    "\n",
    "This is the repository to accompany our article:\n",
    "\n",
    "    A comparison of computational methods for detecting bursts in\n",
    "    neuronal spike trains and their application to human stem\n",
    "    cell-derived neuronal network\n",
    "\n",
    "    Ellese Cotterill, Paul Charlesworth, Christopher W. Thomas, Ole\n",
    "    Paulsen, Stephen J. Eglen\n",
    "\t\n",
    "    J. Neurophysiol. (2016).\n",
    "\n",
    "\n",
    "[Journal web page](http://jn.physiology.org/content/116/2/306)\n",
    "\n",
    "You are free to use any of the data or resources in this repository.\n",
    "We do request however that if you use this material, you cite the\n",
    "above paper in any work that you publish.\n",
    "\n",
    "Code to implement the eight burst detection methods in the paper are located in [Burst_detection_methods](Burst_detection_methods).\n",
    "\n",
    "Data for mouse RGC analysis from Demas et al., 2003 are available from http://www.gigasciencejournal.com/content/3/1/3\n",
    "\n",
    "MEA recordings from hiPSC-derived neuronal networks are located in [hiPSC_recordings](hiPSC_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rpy2 generates a bunch of annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.ipython\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make some test spike trains (or import real data)\n",
    "spikes = np.random.poisson(0.1*np.ones(10000))\n",
    "spike_times =  np.where(spikes>0)[0]\n",
    "spike_times = spike_times/200.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R require(pracma)\n",
    "%R require(sjemea)\n",
    "%R require(e1071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most useful methods are LogISI (adaptive burst-detection with a single tuning parameter) and MI (5 human-interpretable parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#Function to run logISI method - works\n",
    "logisi.pasq.method<-function(spike.train, cutoff=0.1){\n",
    "  cutoff<-ifelse(is.null(cutoff), 0.1, cutoff)\n",
    "  if (length(spike.train)>3) {\n",
    "      isi.low <- logisi.break.calc(spike.train, cutoff) #Calculates threshold as isi.low\n",
    "    if (is.null(isi.low) || isi.low>=1 ){\n",
    "      logisi.par <- list(min.ibi=0,   min.durn=0, min.spikes=3,\n",
    "      isi.low=cutoff) #If no value for isi.low found, or isi.low above 1 second, find bursts using threshold equal to cutoff (default 100ms)\n",
    "      result<-logisi.find.burst(spike.train, logisi.par)\n",
    "    } else if (isi.low<0) {\n",
    "      result<-NA\n",
    "    } else if (isi.low>cutoff & isi.low <1) {\n",
    "      logisi.par <- list(min.ibi=isi.low,   min.durn=0, min.spikes=3,\n",
    "                         isi.low=cutoff) #If isi.low >cutoff, find bursts using threshold equal to cutoff (default 100ms)\n",
    "      bursts<-logisi.find.burst(spike.train, logisi.par)\n",
    "      if (!is.na(bursts)[1]){\n",
    "        logisi.par2 <- list(min.ibi=0,   min.durn=0, min.spikes=3,\n",
    "        isi.low=isi.low) #If bursts have been found, add burst related spikes using threshold of isi.low\n",
    "        brs<-logisi.find.burst(spike.train, logisi.par2)\n",
    "        result<-add.brs(bursts, brs, spike.train)\n",
    "      } else {\n",
    "        result<-bursts\n",
    "      }\n",
    "    } else {\n",
    "      logisi.par <- list(min.ibi=0,   min.durn=0, min.spikes=3,\n",
    "      isi.low=isi.low) #If isi.low<cutoff, find bursts using a threshold equal to isi.low\n",
    "      result<-logisi.find.burst(spike.train, logisi.par)\n",
    "    }\n",
    "    \n",
    "  } else {\n",
    "    result<-NA\n",
    "  }\n",
    "  result\n",
    "}\n",
    "\n",
    "#Finds peaks in logISI histogram\n",
    "get.peaks<-function(h, Pd=2, Th=0, Np=NULL){\n",
    "  m<-0\n",
    "  L<-length(h$density)\n",
    "  j<-0\n",
    "  Np<-ifelse(is.null(Np), L, Np)\n",
    "  pks<-NULL\n",
    "  locs<-NULL\n",
    "  void.th<-0.7\n",
    "  while((j<L)&&(m<Np)){\n",
    "    j<-j+1\n",
    "    endL<-max(1,j-Pd)\n",
    "    if (m>0 && j<min(c(locs[m]+Pd, L-1))){\n",
    "      j<-min(c(locs[m]+Pd, L-1))\n",
    "      endL<-j-Pd\n",
    "    }\n",
    "    endR<-min(L, j+Pd)\n",
    "    temp<-h$density[endL:endR]\n",
    "    aa<-which(j==endL:endR)\n",
    "    temp[aa]<--Inf\n",
    "    if (Pd>1){\n",
    "      idx1<-max(1, aa-2)\n",
    "      idx2<-min(aa+2, length(temp))\n",
    "      idx3<-max(1, aa-1)\n",
    "      idx4<-min(aa+1, length(temp))\n",
    "      if (sum((h$density[j]>(temp[c(1:idx1, idx2:length(temp))]+Th))==FALSE)==0 && sum((h$density[j]>(temp[idx3:idx4]))==FALSE)==0 && j!=1 && j!=L){\n",
    "        m<-m+1\n",
    "        pks[m]<-h$density[j]\n",
    "        locs[m]<-j\n",
    "      } } else if (sum((h$density[j]>(temp+Th))==FALSE)==0 ) {\n",
    "        m<-m+1\n",
    "        pks[m]<-h$density[j]\n",
    "        locs[m]<-j\n",
    "      }\n",
    "    \n",
    "  }\n",
    "  ret<-data.frame(pks=pks, locs=locs)\n",
    "}\n",
    "\n",
    "#Function to find cutoff threshold.\n",
    "find.thresh<-function(h, ISITh=100){\n",
    "  void.th<-0.7\n",
    "  gp<-get.peaks(h)\n",
    "  num.peaks<-length(gp$pks)\n",
    "  pkx<-h$breaks[gp$locs]\n",
    "  intra.indx<-which(pkx<ISITh)\n",
    "  if(length(intra.indx)>=1){\n",
    "    max.intra<-max(gp$pks[intra.indx])\n",
    "    max.idx<-which.max(gp$pks[intra.indx])\n",
    "  } else {\n",
    "    return(-1000)\n",
    "  }\n",
    "  x1<-pkx[max.idx]\n",
    "  y1<-max.intra\n",
    "  locs1<-gp$locs[max.idx]\n",
    "  num.peaks.after.burst<-num.peaks-max.idx\n",
    "  if (num.peaks.after.burst==0){\n",
    "    return(NULL)\n",
    "  } else {\n",
    "    gp2<-gp[(max.idx+1):num.peaks,]\n",
    "    ymin<-sapply(gp2$locs, function(x) min(h$density[locs1:x]))\n",
    "    xmin<-sapply(gp2$locs, function(x) which.min(h$density[locs1:x]))+locs1-1\n",
    "    voidParameter<-1-(ymin/sqrt(y1*gp2$pks))\n",
    "  }\n",
    "  indxvoid<-suppressWarnings(min(which(voidParameter>=void.th)))\n",
    "  if(is.infinite(indxvoid)) {\n",
    "    flags<-c(1,0)\n",
    "    return(NULL)\n",
    "  } else {\n",
    "    ISImax<-h$breaks[xmin[indxvoid]]\n",
    "    return(ISImax)\n",
    "  }\n",
    "}\n",
    "\n",
    "#Calculates cutoff for burst detection\n",
    "logisi.break.calc<-function(st, cutoff){\n",
    "  isi<-diff(st)*1000\n",
    "  max.isi<-ceiling(log10(max(isi)))\n",
    "  isi<-isi[isi>=1]\n",
    "  br<-logspace(0, max.isi, 10*max.isi)\n",
    "  h<-hist(isi, breaks=br, plot=FALSE)\n",
    "  h$density<-h$counts/sum(h$counts)\n",
    "  h$density<-lowess(h$density, f=0.05)$y\n",
    "  thr<-find.thresh(h, cutoff*1000)\n",
    "  if(!is.null(thr)){\n",
    "    thr<-thr/1000\n",
    "  }\n",
    "  thr\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###Function to add burst related spikes to edges of bursts\n",
    "add.brs<-function(bursts, brs, spike.train){\n",
    "is.between<-function(x,a,b){ betw<-0\n",
    "                             if(x>=a &x<=b)\n",
    "                             {\n",
    "                               betw<-1\n",
    "                             }\n",
    "                             betw\n",
    "}\n",
    "                             \n",
    "burst.adj<-data.frame(beg=rep(0, dim(bursts)[1]), end=rep(0, dim(bursts)[1]) )\n",
    "for (i in 1:dim(bursts)[1]) {\n",
    "  for (j in 1:dim(brs)[1]) {\n",
    "    if(is.between(bursts[i,1], brs[j,1], brs[j,2]) | is.between(bursts[i,2], brs[j,1], brs[j,2]))\n",
    "    {\n",
    "      burst.adj$beg[i]<-min(bursts[i,1], brs[j,1])\n",
    "      burst.adj$end[i]<-max(bursts[i,2], brs[j,2])\n",
    "      break\n",
    "    } else {\n",
    "      burst.adj$beg[i]<-bursts[i,1]\n",
    "      burst.adj$end[i]<-bursts[i,2]\n",
    "    }\n",
    "    if(brs[j,2]>bursts[i,2]) {\n",
    "      break\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "diff.begs<-diff(burst.adj[,\"beg\"])\n",
    "rep.bursts.begs<-which(diff.begs==0)\n",
    "if (any(rep.bursts.begs)) {\n",
    "  burst.adj<-burst.adj[-rep.bursts.begs,]\n",
    "}\n",
    "diff.ends<-diff(burst.adj[,\"end\"])\n",
    "rep.bursts.end<-which(diff.ends==0)+1\n",
    "if (any(rep.bursts.end)) {\n",
    "  burst.adj<-burst.adj[-rep.bursts.end,]\n",
    "}\n",
    "start.times<-spike.train[burst.adj$beg]\n",
    "end.times<- spike.train[burst.adj$end]\n",
    "durn<-end.times-start.times\n",
    "len<-burst.adj$end-burst.adj$beg+1\n",
    "mean.isis<-durn/(len-1)\n",
    "N.burst<-dim(burst.adj)[1]\n",
    "IBI<-c(NA, start.times[-1]-end.times[-N.burst])\n",
    "result<-cbind(beg=burst.adj$beg, end=burst.adj$end, IBI=IBI, len=len, durn=durn, mean.isis=mean.isis, SI=rep(1, N.burst))\n",
    "result\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "##Function for finding bursts, taken from sjemea\n",
    "logisi.find.burst<- function(spikes, par, debug=FALSE) {\n",
    "  \n",
    "  ## For one spike train, find the burst using log isi method.\n",
    "  ## e.g.\n",
    "  ## find.bursts(s$spikes[[5]])\n",
    "  ## init.\n",
    "  ## params currently in LOGISI.PAR\n",
    "  ##\n",
    "  \n",
    "  no.bursts = NA;                       #value to return if no bursts found.\n",
    "  \n",
    "  \n",
    "  ##beg.isi =    par$beg.isi\n",
    "  ##end.isi =    par$end.isi\n",
    "  min.ibi =      par$min.ibi\n",
    "  min.durn =     par$min.durn\n",
    "  min.spikes =   par$min.spikes\n",
    "  isi.low =      par$isi.low\n",
    "  \n",
    "  nspikes = length(spikes)\n",
    "  \n",
    "  ## Create a temp array for the storage of the bursts.  Assume that\n",
    "  ## it will not be longer than Nspikes/2 since we need at least two\n",
    "  ## spikes to be in a burst.\n",
    "  \n",
    "  max.bursts <- floor(nspikes/2)\n",
    "  bursts <- matrix(NA, nrow=max.bursts, ncol=3)\n",
    "  colnames(bursts) = c(\"beg\", \"end\", \"IBI\")\n",
    "  burst <- 0                            #current burst number\n",
    "  \n",
    "  ## Phase 1 -- burst detection. Each interspike interval of the data\n",
    "  ## is compared with the threshold THRE. If the interval is greater\n",
    "  ## than the threshold value, it can not be part of a burst; if the\n",
    "  ## interval is smaller or equal to the threhold, the interval may be\n",
    "  ## part of a burst.\n",
    "  \n",
    "  \n",
    "  \n",
    "  ## LAST.END is the time of the last spike in the previous burst.\n",
    "  ## This is used to calculate the IBI.\n",
    "  ## For the first burst, this is no previous IBI\n",
    "  last.end = NA;                        #for first burst, there is no IBI.\n",
    "  \n",
    "  eps<-10^(-10)\n",
    "  n = 2\n",
    "  in.burst = FALSE\n",
    "  \n",
    "  while ( n < nspikes) {\n",
    "    \n",
    "    next.isi = spikes[n] - spikes[n-1]\n",
    "    if (in.burst) {\n",
    "      if (next.isi - isi.low>eps) {\n",
    "        ## end of burst\n",
    "        end = n-1; in.burst = FALSE\n",
    "        \n",
    "        \n",
    "        ibi =  spikes[beg] - last.end; last.end = spikes[end]\n",
    "        res = c(beg, end, ibi)\n",
    "        burst = burst + 1\n",
    "        if (burst > max.bursts) {\n",
    "          print(\"too many bursts!!!\")\n",
    "          browser()\n",
    "        }\n",
    "        bursts[burst,] <- res\n",
    "      }\n",
    "    } else {\n",
    "      ## not yet in burst.\n",
    "      if (next.isi - isi.low <=eps) {\n",
    "        ## Found the start of a new burst.\n",
    "        beg = n-1; in.burst = TRUE\n",
    "      }\n",
    "    }\n",
    "    n = n+1\n",
    "  }\n",
    "  \n",
    "  ## At the end of the burst, check if we were in a burst when the\n",
    "  ## train finished.\n",
    "  if (in.burst) {\n",
    "    end = nspikes\n",
    "    ibi =  spikes[beg] - last.end\n",
    "    res = c(beg, end, ibi)\n",
    "    burst = burst + 1\n",
    "    if (burst > max.bursts) {\n",
    "      print(\"too many bursts!!!\")\n",
    "      browser()\n",
    "    }\n",
    "    bursts[burst,] <- res\n",
    "  }\n",
    "  \n",
    "  ## Check if any bursts were found.\n",
    "  if (burst > 0 ) {\n",
    "    ## truncate to right length, as bursts will typically be very long.\n",
    "    bursts = bursts[1:burst,,drop=FALSE]\n",
    "  } else {\n",
    "    ## no bursts were found, so return an empty structure.\n",
    "    return(no.bursts)\n",
    "  }\n",
    "  \n",
    "  if (debug) {\n",
    "    print(\"End of phase1\\n\")\n",
    "    print(bursts)\n",
    "  }\n",
    "  \n",
    "  \n",
    "  ## Phase 2 -- merging of bursts.  Here we see if any pair of bursts\n",
    "  ## have an IBI less than MIN.IBI; if so, we then merge the bursts.\n",
    "  ## We specifically need to check when say three bursts are merged\n",
    "  ## into one.\n",
    "  \n",
    "  \n",
    "  ibis = bursts[,\"IBI\"]\n",
    "  merge.bursts = which(ibis < min.ibi)\n",
    "  \n",
    "  if (any(merge.bursts)) {\n",
    "    ## Merge bursts efficiently.  Work backwards through the list, and\n",
    "    ## then delete the merged lines afterwards.  This works when we\n",
    "    ## have say 3+ consecutive bursts that merge into one.\n",
    "    \n",
    "    for (burst in rev(merge.bursts)) {\n",
    "      bursts[burst-1, \"end\"] = bursts[burst, \"end\"]\n",
    "      bursts[burst, \"end\"] = NA         #not needed, but helpful.\n",
    "    }\n",
    "    bursts = bursts[-merge.bursts,,drop=FALSE] #delete the unwanted info.\n",
    "  }\n",
    "  \n",
    "  if (debug) {\n",
    "    print(\"End of phase 2\\n\")\n",
    "    print(bursts)\n",
    "  }\n",
    "  \n",
    "  \n",
    "  ## Phase 3 -- remove small bursts: less than min duration (MIN.DURN), or\n",
    "  ## having too few spikes (less than MIN.SPIKES).\n",
    "  ## In this phase we have the possibility of deleting all spikes.\n",
    "  \n",
    "  ## LEN = number of spikes in a burst.\n",
    "  ## DURN = duration of burst.\n",
    "  len = bursts[,\"end\"] - bursts[,\"beg\"] + 1\n",
    "  durn = spikes[bursts[,\"end\"]] - spikes[bursts[,\"beg\"]]\n",
    "  bursts = cbind(bursts, len, durn)\n",
    "  \n",
    "  rejects = which ( (durn < min.durn) | ( len < min.spikes) )\n",
    "  \n",
    "  if (any(rejects)) {\n",
    "    bursts = bursts[-rejects,,drop=FALSE]\n",
    "  }\n",
    "  \n",
    "  if (nrow(bursts) == 0) {\n",
    "    ## All the bursts were removed during phase 3.\n",
    "    bursts = no.bursts\n",
    "  } else {\n",
    "    ## Compute mean ISIS\n",
    "    len = bursts[,\"end\"] - bursts[,\"beg\"] + 1\n",
    "    durn = spikes[bursts[,\"end\"]] - spikes[bursts[,\"beg\"]]\n",
    "    mean.isis = durn/(len-1)\n",
    "    \n",
    "    ## Recompute IBI (only needed if phase 3 deleted some cells).\n",
    "    if (nrow(bursts)>1) {\n",
    "      ibi2 = c(NA, calc.ibi(spikes, bursts))\n",
    "    } else {\n",
    "      ibi2 = NA\n",
    "    }\n",
    "    bursts[,\"IBI\"] = ibi2\n",
    "    \n",
    "    SI = rep(1, length(mean.isis ))\n",
    "    bursts = cbind(bursts, mean.isis, SI)\n",
    "  }\n",
    "  \n",
    "  ## End -- return burst structure.\n",
    "  bursts\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "##Poisson Surprise (PS) method - WORKS\n",
    "\n",
    "PS.method<-function(spike.train, si.thresh=5) {\n",
    "    si.thresh<-ifelse(is.null(si.thresh), 5, si.thresh)\n",
    "    burst <- si.find.bursts.thresh(spike.train)\n",
    "    if (is.null(dim(burst))){\n",
    "        result<-NA\n",
    "    } else {\n",
    "        burst.rem<-which(burst[,\"SI\"]<si.thresh)\n",
    "        if (length(burst.rem)) {\n",
    "            burst<-burst[-burst.rem,]\n",
    "        }\n",
    "        if (length(dim(burst))<1) {\n",
    "            burst<-data.frame(beg=burst[1], len=burst[2], SI=burst[3], durn=burst[4], mean.isis=burst[5])\n",
    "        } else if (dim(burst)[1]==0){\n",
    "            return(NA)\n",
    "        }\n",
    "        beg<-burst[,\"beg\"]\n",
    "        len<-burst[,\"len\"]\n",
    "        N.burst<-length(beg)\n",
    "        end<-beg+len-1\n",
    "        IBI<-c(NA, spike.train[beg[-1]]-spike.train[end[-N.burst]])\n",
    "        result<-cbind(beg=beg, end=end, IBI=IBI, len=len, durn=burst[,\"durn\"], mean.isis=burst[,\"mean.isis\"], SI=burst[,\"SI\"])\n",
    "        rownames(result)<-NULL\n",
    "    }\n",
    "    result\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "si.find.bursts.thresh<- function (spikes, debug = FALSE)\n",
    "{\n",
    "    nspikes = length(spikes)\n",
    "    mean.isi = mean(diff(spikes))\n",
    "    threshold = mean.isi/2\n",
    "    n = 1\n",
    "    max.bursts <- floor(nspikes/3)\n",
    "    bursts <- matrix(NA, nrow = max.bursts, ncol = burst.info.len)\n",
    "    burst <- 0\n",
    "    while (n < nspikes - 2) {\n",
    "        if (debug)\n",
    "        print(n)\n",
    "        if (((spikes[n + 1] - spikes[n]) < threshold) && ((spikes[n +\n",
    "        2] - spikes[n + 1]) < threshold)) {\n",
    "            res <- si.find.burst.thresh2(n, spikes, nspikes, mean.isi,\n",
    "            burst.isi.max, debug)\n",
    "            if (is.na(res[1])) {\n",
    "                n <- n + 1\n",
    "            }\n",
    "            else {\n",
    "                burst <- burst + 1\n",
    "                if (burst > max.bursts) {\n",
    "                    print(\"too many bursts\")\n",
    "                    browser()\n",
    "                }\n",
    "                bursts[burst, ] <- res\n",
    "                n <- res[1] + res[2]\n",
    "                names(n) <- NULL\n",
    "            }\n",
    "        }\n",
    "        else {\n",
    "            n = n + 1\n",
    "        }\n",
    "    }\n",
    "    if (burst > 0) {\n",
    "        res <- bursts[1:burst, , drop = FALSE]\n",
    "        colnames(res) <- burst.info\n",
    "    }\n",
    "    else {\n",
    "        res <- NA\n",
    "    }\n",
    "    res\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "si.find.burst.thresh2<-function(n, spikes, nspikes, mean.isi, threshold=NULL,\n",
    "debug=FALSE) {\n",
    "    ## Find a burst starting at spike N.\n",
    "    ## Include a better phase 1.\n",
    "    \n",
    "    \n",
    "    ## Determine ISI threshold.\n",
    "    if (is.null(threshold))\n",
    "    isi.thresh = 2 * mean.isi\n",
    "    else\n",
    "    isi.thresh = threshold\n",
    "    \n",
    "    if (debug)\n",
    "    cat(sprintf(\"** find.burst %d\\n\", n))\n",
    "    \n",
    "    i=3  ## First three spikes are in burst.\n",
    "    s = surprise(n, i, spikes, nspikes, mean.isi)\n",
    "    \n",
    "    ## Phase 1 - add spikes to the train.\n",
    "    phase1 = TRUE\n",
    "    ##browser()\n",
    "    \n",
    "    ## in Phase1, check that we still have spikes to add to the train.\n",
    "    while( phase1 ) {\n",
    "        \n",
    "        ##printf(\"phase 1 s %f\\n\", s);\n",
    "        \n",
    "        i.cur = i;\n",
    "        \n",
    "        ## CHECK controls how many spikes we can look ahead until SI is maximised.\n",
    "        ## This is normally 10, but will be less at the end of the train.\n",
    "        check = min(10, nspikes-(i+n-1))\n",
    "        \n",
    "        looking = TRUE; okay = FALSE;\n",
    "        while (looking) {\n",
    "            \n",
    "            if (check==0) {\n",
    "                ## no more spikes left to check.\n",
    "                looking=FALSE;\n",
    "                break;\n",
    "            }\n",
    "            check=check-1; i=i+1\n",
    "            s.new = surprise(n, i, spikes, nspikes, mean.isi)\n",
    "            if (debug)\n",
    "            printf(\"s.new %f s %f n %d i %d check %d\\n\", s.new, s, n, i, check)\n",
    "            \n",
    "            if (s.new > s) {\n",
    "                okay=TRUE; looking=FALSE;\n",
    "            } else {\n",
    "                ## See if we should keep adding spikes?\n",
    "                if ( (spikes[i] - spikes[i-1]) > isi.thresh ) {\n",
    "                    looking = FALSE;\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "        ## No longer checking, see if we found an improvement.\n",
    "        if (okay) {\n",
    "            if (s > s.new) {\n",
    "                ## This should not happen.\n",
    "                printf(\"before s %f s.new %f\\n\", s, s.new)\n",
    "                browser()\n",
    "            }\n",
    "            s = s.new\n",
    "        } else {\n",
    "            ## Could not add more spikes onto the end of the train.\n",
    "            phase1 = FALSE\n",
    "            i = i.cur\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    ## start deleting spikes from the start of the burst.\n",
    "    phase2 = TRUE\n",
    "    while(phase2) {\n",
    "        if (i==3) {\n",
    "            ## minimum length of a burst must be 3.\n",
    "            phase2=FALSE\n",
    "        } else {\n",
    "            s.new = surprise(n+1, i-1, spikes, nspikes, mean.isi)\n",
    "            if (debug)\n",
    "            cat(sprintf(\"phase 2: n %d i %d s.new %.4f\\n\", n, i, s.new))\n",
    "            if (s.new > s) {\n",
    "                if (debug)\n",
    "                print(\"in phase 2 acceptance\\n\")\n",
    "                n = n+1; i = i-1\n",
    "                s = s.new\n",
    "            } else {\n",
    "                ## removing front spike did not improve SI.\n",
    "                phase2 = FALSE\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    ## End of burst detection; accumulate result.\n",
    "    \n",
    "    \n",
    "    ## compute the ISIs, and then the mean ISI.\n",
    "    \n",
    "    ## Fencepost issue: I is the number of spikes in the burst, so if\n",
    "    ## the first spike is N, the last spike is at N+I-1, not N+I.\n",
    "    isis = diff(spikes[n+(0:(i-1))])\n",
    "    mean.isis = mean(isis)\n",
    "    \n",
    "    durn = spikes[n+i-1] - spikes[n]\n",
    "    res <- c(n=n, i=i, s=s, durn=durn, mean.isis=mean.isis)\n",
    "    \n",
    "    ##browser()\n",
    "    res\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "#Applies mi.find.bursts from sjemea to single spike train\n",
    "MI.method<- function(spike.train){\n",
    "  burst<-mi.find.bursts(spike.train)\n",
    "  if (dim(burst)[1]<1) {\n",
    "    burst<-NA\n",
    "  }\n",
    "  burst\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# WORKS!!!\n",
    "##Function to calculate and plot bursts, based on CMA method (Kapucu et al., 2012).\n",
    "##Input is spike train. If brs.incl is set to true, method will include burst related\n",
    "##spikes. min.val is the minumum number of spikes on a spikes train for the method to be run.\n",
    "##If plot = TRUE, spike train with bursts labelled is plotted.\n",
    "CMA.method<-function(spike.train, brs.incl=TRUE, min.val=3, plot=FALSE) {\n",
    "  #Do not perform burst detection if less than min.val spikes in the spike train\n",
    "  if (length(spike.train)<min.val) {\n",
    "    result<-NA\n",
    "    return(result)\n",
    "  }\n",
    "  isi<-diff(spike.train)\n",
    "  isi.range<-max(isi)-min(isi)\n",
    "  eps<-isi.range/1000\n",
    "  if (isi.range<0.001){\n",
    "    breaks1<-seq(0, max(isi)+isi.range/10, isi.range/10)\n",
    "    hist.isi<-hist(isi, breaks =breaks1, plot=FALSE) #if ISI range very small (<0.001), use smaller bins\n",
    "  } else {\n",
    "    hist.isi<-hist(isi, breaks =seq(0, max(isi)+eps, eps), plot=FALSE) #Create histogram with approx 1000 bins\n",
    "  }\n",
    "  CMA<-cumsum(hist.isi$counts)/seq(1,length(hist.isi$counts),1)\n",
    "  CMAm<-max(CMA)\n",
    "  m<-min(which(CMA==CMAm))\n",
    "  alpha.values<-data.frame(max=c(1, 4, 9, 1000), a1=c(1, 0.7, 0.5, 0.3), a2=c(0.5, 0.5, 0.3,0.1)) #Alpha value scale\n",
    "  skew<-skewness(CMA)\n",
    "  if (is.na(skew)){\n",
    "    result<-NA\n",
    "    return(result)\n",
    "  }\n",
    "  diff.skew<-alpha.values[,\"max\"]-skew\n",
    "  alpha.indx<-which(diff.skew==min(diff.skew[diff.skew>0]))\n",
    "  alpha1<-alpha.values[alpha.indx, \"a1\"]\n",
    "  alpha2<-alpha.values[alpha.indx, \"a2\"]\n",
    "  cutoff<-which.min(abs(CMA[m:length(CMA)] - (alpha1*CMAm)))+(m-1) #Cutoff set at bin closest in value to alpha1*CMAm\n",
    "  xt<-hist.isi$mids[cutoff] #maxISI\n",
    "  cutoff2<-which.min(abs(CMA[m:length(CMA)] - (alpha2*CMAm)))+(m-1) #Burst related spikes cutoff set at bin closest in value to alpha2*CMAm\n",
    "  xt2<-hist.isi$mids[cutoff2] #maxISI for burst related spikes\n",
    "  bursts<-find.bursts(spike.train,xt) #Find burst cores\n",
    "  #If brs.incl=TRUE, then extend bursts to include burst related spikes\n",
    "  if (brs.incl && !is.null(dim(bursts)[1])){\n",
    "    brs<-find.bursts(spike.train, xt2)\n",
    "    burst.adj<-NULL\n",
    "    for (i in 1:dim(bursts)[1]){\n",
    "    burst.between<-apply(brs[,1:2], 1, function(x) between.bursts(bursts[i,1:2], x)) #Find burst related spikes which surround bursts\n",
    "    which.between<-which(unlist(sapply(burst.between, function(x) sum(!is.na(x))))>0)\n",
    "    if (which.between) {\n",
    "      burst.adj<-rbind(burst.adj, burst.between[[which.between]])\n",
    "    } else {\n",
    "      burst.adj<-rbind(burst.adj, bursts[i, 1:2])\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  burst.adj<-unique(burst.adj) #Remove any repeated bursts\n",
    "  N<-dim(burst.adj)[1]\n",
    "  beg<-burst.adj[,1]\n",
    "  end<-burst.adj[,2]\n",
    "  ibi<-c(NA, spike.train[beg[-1]]-spike.train[end[-N]])\n",
    "  len<-end-beg+1\n",
    "  durn<-spike.train[end]-spike.train[beg]\n",
    "  bursts<-cbind(beg=beg, end=end, IBI=ibi, len=len, durn=durn, mean.isis=durn/len, SI=1)\n",
    "  }\n",
    "\n",
    "  if (is.null(dim(bursts)[1])){\n",
    "    bursts<-NA\n",
    "  }\n",
    "  bursts\n",
    "}\n",
    "  \n",
    "    \n",
    "    between.bursts<-function(burst1, burst2) {\n",
    "      if (burst2[1]<=burst1[1] & burst2[2]>=burst1[2]) {\n",
    "        burst<-c(min(burst1[1], burst2[1]), max(burst2[1], burst2[2]))\n",
    "      } else {\n",
    "        burst<-NA\n",
    "      }\n",
    "      burst\n",
    "    }\n",
    "    \n",
    "    #Add back in IBIs\n",
    "\n",
    "find.bursts<-function(spike.train, xt){\n",
    "isi<-diff(spike.train)\n",
    "indxs<-which(isi<xt)\n",
    "burst.breaks<- c(0, which(diff(indxs) >1), length(indxs))\n",
    "isi.list<-sapply(seq(length(burst.breaks) - 1), function(i) indxs[(burst.breaks[i] + 1):burst.breaks[i+1]])\n",
    "burst.indx<-which(sapply(isi.list, length)>1)\n",
    "if(length(burst.indx)){\n",
    "beg<-sapply(isi.list[burst.indx], function(x) min(x))\n",
    "end<-sapply(isi.list[burst.indx], function(x) max(x))+1\n",
    "N<-length(beg)\n",
    "ibi<-c(NA, spike.train[beg[-1]]-spike.train[end[-N]])\n",
    "len<-end-beg+1\n",
    "durn<-spike.train[end]-spike.train[beg]\n",
    "bursts<-cbind(beg=beg, end=end, IBI=ibi, len=len, durn=durn, mean.isis=durn/(len-1), SI=1)\n",
    "} else {\n",
    "  bursts<-NA\n",
    "}\n",
    "bursts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "# WORKS!!!\n",
    "##\n",
    "# An R implementation of Gourevitch & Eggermont (2007) Rank Surprise Method for \n",
    "# identifying bursts in spike trains.\n",
    "#\n",
    "# Arguments:\n",
    "# spike.train = vector of spike timings\n",
    "# RS.thresh   = significance threshold for accepting a burst\n",
    "#\n",
    "# Returns:\n",
    "# A list of 2 column matrices of the start and end times of identified bursts for\n",
    "# each value of RS.thresh provided. \n",
    "# A 2x2 matrix of -1 is returned whenever no bursts are found.\n",
    "##\n",
    "\n",
    "RS.method <- function(spike.train, RS.thresh){\n",
    "  \n",
    "  ISI <- diff(spike.train)\n",
    "  N <- length(ISI)\n",
    "  Results<-list()\n",
    "  if (N>1) {\n",
    "  # Burst size at which Gaussian approximation is used\n",
    "  q.lim <- 30\n",
    "  # Minimum number of spikes acceptable as a burst\n",
    "  l.min <- 3\n",
    "  # Maximum ISI identifying spikes as possible bursts for subsequent analysis\n",
    "  limit <- quantile(ISI,0.75)\n",
    "  \n",
    "  # Convert ISI values to ranks\n",
    "  order1 <- sort(ISI,index.return=T)$ix\n",
    "  order2 <- sort(-ISI,index.return=T)$ix\n",
    "  rk <- rep(0,N)\n",
    "  rk2 <- rep(0,N)\n",
    "  rk[order1] <- (1:N)\n",
    "  rk2[order2] <- (1:N)\n",
    "  R=(N+1-rk2+rk)/2  # ensures equal values given mean rank\n",
    "  \n",
    "  #Identify start and end points of spikes sequences below limit\n",
    "  ISI.limit <- diff(ISI<limit)\n",
    "  begin.int <- which(ISI.limit==1)+1\n",
    "  end.int <- which(ISI.limit==-1)\n",
    "  #Include first ISI if under limit\n",
    "  if(ISI[1] < limit){\n",
    "    begin.int <- c(1,begin.int)\n",
    "  }\n",
    "  #Include last ISI if spikes are below limit at end of spike train\n",
    "  if(length(end.int) < length(begin.int)){\n",
    "    end.int <- c(end.int,N)\n",
    "  }\n",
    "  #Number of spikes in each putative burst\n",
    "  length.int <- end.int-begin.int+1\n",
    "  \n",
    "  # Create stores for final burst information\n",
    "  burst.RS <-  numeric()\n",
    "  burst.length <- numeric()\n",
    "  burst.start <- numeric()\n",
    "  \n",
    "  # Create solutions to -1^k \n",
    "  alternate <- rep(c(1,-1),200)\n",
    "  \n",
    "  # Create solutions to log factorials\n",
    "  log.fac <- cumsum(log(1:q.lim))\n",
    "  \n",
    "  for (index in 1:length(begin.int)){  # Repeat for all clusters of short ISIs\n",
    "    n.j <- begin.int[index]\n",
    "    p.j <- length.int[index];\n",
    "    subseq.RS <- numeric()\n",
    "    if (p.j >= (l.min-1)){\t\t # Proceed only if there are enough spikes\n",
    "      for (i in 0:(p.j-(l.min-1))){  # Repeat for all possible first spikes\n",
    "        q <- l.min-2\n",
    "        while (q < p.j-i){       # Repeat for increasing burst lengths\n",
    "          q <- q+1\n",
    "          rr <- seq(n.j+i, n.j+i+q-1)\n",
    "          u <- sum(R[rr])\n",
    "          u <- floor(u)\n",
    "          # Calculate RS probability exactly, if q is small\n",
    "          # or approximately if q is large\n",
    "          if (q < q.lim){\n",
    "            k <- seq(0,(u-q)/N,1)\n",
    "            length.k <- length(k)\n",
    "            mat1 <- matrix(rep(k,q), q, length.k, byrow=T)*N\n",
    "            mat2 <- matrix(rep(0:(q-1), length.k), q, length.k)\n",
    "            p <- exp((colSums(log(u - mat1 - mat2)) - \n",
    "                        log.fac[c(1,k[-1])] - log.fac[q-k]) - \n",
    "                       q*log(N))%*%alternate[1:length.k]                 \n",
    "          }else{\n",
    "            p <- pnorm((u-q*(N+1)/2)/sqrt(q*(N^2-1)/12));\n",
    "          }\n",
    "          RS <- -log(p)\n",
    "          subseq.RS <- rbind(subseq.RS, c(RS,i,q))\n",
    "        }\n",
    "      }\n",
    "      # Extract the highest rank surprise bursts that are non-overlapping \n",
    "      subseq.RS <- matrix(subseq.RS,ncol=3)\n",
    "      if (length(subseq.RS) > 0){  \n",
    "        subseq.RS <- subseq.RS[order(subseq.RS[ ,1], decreasing=T), ]\n",
    "        while (length(subseq.RS) > 0){\n",
    "          subseq.RS <- matrix(subseq.RS, ncol=3)\n",
    "          current.burst <- subseq.RS[1, ]\n",
    "          burst.RS <- rbind(burst.RS,current.burst[1])\n",
    "          burst.start <- rbind(burst.start, n.j+current.burst[2])\n",
    "          burst.length <- rbind(burst.length, current.burst[3]+1)\n",
    "          subseq.RS <- subseq.RS[-1, ]\n",
    "          if (length(subseq.RS) > 0){ \n",
    "            subseq.RS <- matrix(subseq.RS, ncol=3)  \n",
    "            keep <- which(subseq.RS[ ,2] + subseq.RS[ ,3] - 1 < \n",
    "                            current.burst[2] | subseq.RS[,2] >  \n",
    "                            current.burst[2] + current.burst[3] -1)\n",
    "            subseq.RS=subseq.RS[keep, ]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    " \n",
    "  # Convert length into end position and positions into times\n",
    "  for (x in 1:length(RS.thresh)){\n",
    "  above.thresh<-which(burst.RS>=RS.thresh[x])\n",
    "  N.burst<-length(above.thresh)\n",
    "  if (N.burst<1) {\n",
    "    result<-NA\n",
    "  } else {\n",
    "    bursts<-cbind(burst.start[above.thresh], burst.length[above.thresh])\n",
    "   bursts.ord<-cbind(bursts[ order(bursts[,1]),1], bursts[ order(bursts[,1]),2])\n",
    "  beg<-bursts.ord[,1]\n",
    "  len<-bursts.ord[,2]\n",
    "  end<-beg+len-1\n",
    "  start.times<-spike.train[beg]\n",
    "  end.times<-spike.train[end]\n",
    "  IBI<-c(NA, start.times[-1]-end.times[-N.burst])\n",
    "  durn<-end.times-start.times\n",
    "  mean.isis<-durn/(len-1)\n",
    "  result<-cbind(beg=beg, end=end, IBI=IBI, len=len, durn=durn, mean.isis=mean.isis, SI=rep(RS.thresh[x], N.burst))\n",
    "  }\n",
    "  Results[[x]]<-result\n",
    "  }\n",
    "  } else {\n",
    "    Results<-rep(list(NA), length(RS.thresh))\n",
    "  }\n",
    "  \n",
    "  \n",
    "  return(Results)\n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#ISI Rank threshold method WORKS\n",
    "hennig.method<-function(st, cutoff.prob=0.05) {\n",
    "  bursts<-NULL\n",
    "  result<-NULL\n",
    "  allisi<-diff(st)\n",
    "  if (length(allisi)<1) {\n",
    "    result<- NA\n",
    "  } else {\n",
    "  isi.rank<-rank(allisi) #1 is smallest ISI\n",
    "  st.length<-ceiling(max(st))\n",
    "  spike.counts<-NULL\n",
    "  for (i in 0:st.length-1) {\n",
    "    spike.counts[i+1]<-sum((st>=i)*(st<(i+1))) #calculate spike count of 1s intervals\n",
    "  }\n",
    "  sc.hist<-hist(spike.counts, nclass=200, plot=FALSE)\n",
    "  p.dist<-1-cumsum(sc.hist$counts/sum(sc.hist$counts)) \n",
    "  cutoff.indx<-sum(p.dist>cutoff.prob)\n",
    "  theta.c<-max(c(2, ceiling(sc.hist$mids[cutoff.indx]))) #set theta_C to value where probability of spike counts is equal to cutoff.index (default 0.05)\n",
    "  theta.c.end<-theta.c*0.5 #cutoff to end a burst\n",
    "  isi.rel.rank<-isi.rank/max(isi.rank) #calculate relative rank of each isi\n",
    "  \n",
    "  t<-st\n",
    "  j<-1\n",
    "  burst.on<-0\n",
    "  bc<-1\n",
    "  dt<-1\n",
    "  burst.time<-NULL\n",
    "  burst.end<-NULL\n",
    "  burst.dur<-NULL\n",
    "  burst.size<-NULL\n",
    "  burst.beg<-NULL\n",
    "  while (j<length(allisi)-theta.c) {\n",
    "    if (burst.on==0 && isi.rel.rank[j]<0.5) { #burst begins when rank of isi<0.5\n",
    "      if (t[j+theta.c]<t[j]+dt){ \n",
    "        burst.on<-1\n",
    "        burst.time[bc]<-t[j]\n",
    "        burst.beg[bc]<-j\n",
    "        brc<-j\n",
    "      }\n",
    "    } else if (burst.on==1) { \n",
    "      if (t[j+theta.c.end]>t[j]+dt) {\n",
    "        burst.end[bc]<-t[j]\n",
    "        burst.dur[bc]<-t[j]-burst.time[bc]\n",
    "        burst.size[bc]<-j-brc\n",
    "        bc<-bc+1\n",
    "        burst.on<-0\n",
    "      }\n",
    "    }\n",
    "    j<-j+1\n",
    "  }\n",
    "  if (burst.on==1) {\n",
    "    tmp<-t[j]-burst.time[bc]\n",
    "    burst.end[bc]<-burst.time[bc]+tmp\n",
    "    burst.dur[bc]<-t[j]-burst.time[bc]\n",
    "    burst.size[bc]<-j-brc\n",
    "    bc<-bc+1\n",
    "  }\n",
    "  N.burst<-length(burst.time)\n",
    "  if (N.burst<1) {\n",
    "    result<-NA\n",
    "  } else {\n",
    "  end<-burst.beg+burst.size\n",
    "  IBI<-c(NA, burst.time[-1]-burst.end[-N.burst])\n",
    "  len<-burst.size+1\n",
    "  mean.isis<-burst.dur/(len-1)\n",
    "  result<-cbind(beg=burst.beg, end=end, IBI=IBI, len=len, durn=burst.dur, mean.isis=mean.isis, SI=rep(1, N.burst))\n",
    "  }\n",
    "  }\n",
    "  result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "from io import StringIO\n",
    "import sys\n",
    "\n",
    "#function converting output matrix to data frame\n",
    "\n",
    "def Matrix2DF(mat):   \n",
    "    r_columns = [c for c in mat.colnames]\n",
    "    columns = [c.replace('.', '_')  for c in r_columns]\n",
    "    df = {}\n",
    "    for i,c in enumerate(columns):\n",
    "        column =  mat.rx(True, r_columns[i])\n",
    "        df[c] = [x for x in column]\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "## Helper functions that simplify calling the burst detection methods\n",
    "\n",
    "def Henning(sp_times, cutoff=0.05):\n",
    "    print('Rank Thresholding Method')\n",
    "    %R -i sp_times\n",
    "    %R -i cutoff\n",
    "    %R bursts = hennig.method(sp_times, cutoff)\n",
    "    burst_frame = %Rget bursts\n",
    "    return Matrix2DF(burst_frame)\n",
    "\n",
    "def RankSurprise(sp_times, threshold=5): #works sometimes, but is generally problematic!\n",
    "    print('Rank Surprise Method')\n",
    "    old_stdout = sys.stdout\n",
    "    result = StringIO()\n",
    "    sys.stdout = result\n",
    "    %R -i sp_times\n",
    "    %R -i threshold\n",
    "    %R bursts = RS.method(sp_times, threshold)\n",
    "    burst_frame = %Rget bursts\n",
    "    print(burst_frame)\n",
    "    sys.stdout = old_stdout   \n",
    "    return pd.read_csv(StringIO(result.getvalue()), header=1, delim_whitespace = True)\n",
    "    #Strange formatting issue on the output - had to parse PRINT output\n",
    "\n",
    "    \n",
    "def CMA(sp_times, includeBorders=True, minimum=3, plot=False):\n",
    "    #print('Cummulative Moving Average')\n",
    "    %R -i sp_times\n",
    "    %R -i includeBorders\n",
    "    %R -i minimum\n",
    "    %R -i plot\n",
    "    %R bursts = CMA.method(sp_times, includeBorders, minimum, plot)\n",
    "    burst_frame = %Rget bursts\n",
    "    return Matrix2DF(burst_frame)\n",
    "\n",
    "\n",
    "def LogISI(sp_times, cutoff=0.1):\n",
    "    #print('LogISI method')\n",
    "    %R -i sp_times\n",
    "    %R -i cutoff\n",
    "    %R bursts = logisi.pasq.method(sp_times, cutoff)\n",
    "    burst_frame = %Rget bursts\n",
    "    return Matrix2DF(burst_frame)\n",
    "\n",
    "def PoissonSurprise(sp_times, threshold=5):\n",
    "    #print('Poisson Surprise Method')\n",
    "    %R -i sp_times\n",
    "    %R -i threshold\n",
    "    %R bursts = PS.method(sp_times, threshold)\n",
    "    burst_frame = %Rget bursts\n",
    "    return Matrix2DF(burst_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing functions implemented above on a synthetic spiketrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Henning(spike_times, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RankSurprise(spike_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CMA(spike_times, True, 3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogISI(spike_times, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PoissonSurprise(spike_times, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Parameterize this so that you can pick which burst detection method and what paramters to feed it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell and the cells immediately below it are my (Marcus') code. Other than commenting out\n",
    "# some unneeded lines, these cells are the only modifications I made to this script.\n",
    "# In order to get these cells to run, you have to run all the cells above them first.\n",
    "# -Marcus\n",
    "\n",
    "# Imports\n",
    "import src.SessionNavigator as SessionNavigator\n",
    "import src.SessionProcessor as SessionProcessor\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "# Insert the file path to your data (e.g. \"C:\\Users\\MickeyMouse\\MouseBrainData\\manifest.json\")\n",
    "data_root = \"C:/Users/Demogorgon/Documents/College/Marcus/Boston University PhD/Ocker Lab\"\n",
    "manifest_path = f\"{data_root}/AllenSDK_Data/manifest.json\"\n",
    "save_path = f\"{data_root}/correlations_and_bursts/data\"\n",
    "SAVE = True\n",
    "\n",
    "# Create a SessionNavigator, which will open and navigate the data in manifest_path\n",
    "navigator = SessionNavigator.SessionNavigator(manifest_path)\n",
    "\n",
    "# The SessionNavigator has simple search functions to find sessions with specific criteria.\n",
    "# Sessions can be sorted by visual areas observed (acronyms), mouse genotype, and \n",
    "# session type (either \"functional_connectivity\" or \"brain_observatory_1.1\")\n",
    "acronyms = ['VISp', 'VISl', 'VISal', 'VISrl', 'VISam', 'VISpm', 'LGd']\n",
    "session_type = \"functional_connectivity\"\n",
    "genotype = \"wt/wt\"\n",
    "session_ids = navigator.find_sessions(acronyms, genotype=genotype, session_type=session_type)\n",
    "#sessions = [navigator.load_session(session_id) for session_id in session_ids]\n",
    "\n",
    "# Load the session and open a SessionProcessor\n",
    "current_session = session_ids[0]\n",
    "\n",
    "session = navigator.load_session(current_session)\n",
    "processor = SessionProcessor.SessionProcessor(session)\n",
    "\n",
    "# We'll look at just one stimulus type here\n",
    "stim = 'drifting_gratings_contrast'\n",
    "stim_table = session.get_stimulus_table(stim)\n",
    "stim_presentation_ids = stim_table.index.values\n",
    "#stim_presentation_ids = stim_presentation_ids[:10]\n",
    "spike_trains = session.presentationwise_spike_times(stim_presentation_ids, processor.all_units)\n",
    "num_units = len(processor.all_units)\n",
    "#one_unit_trains = spike_trains[spike_trains['unit_id']==951032492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1m 8s. 100/784 burst trains separated from single trains.\n",
      "Time elapsed: 2m 29s. 200/784 burst trains separated from single trains.\n",
      "Time elapsed: 3m 48s. 300/784 burst trains separated from single trains.\n",
      "Time elapsed: 5m 12s. 400/784 burst trains separated from single trains.\n",
      "Time elapsed: 6m 40s. 500/784 burst trains separated from single trains.\n",
      "Time elapsed: 8m 11s. 600/784 burst trains separated from single trains.\n",
      "Time elapsed: 9m 35s. 700/784 burst trains separated from single trains.\n",
      "708/784 burst trains separated from single trains. Total time elapsed: 11m 3s.\n",
      "76/784 separations could not be completed.\n",
      "Saving whole unit burst trains to:\n",
      "C:/Users/Demogorgon/Documents/College/Marcus/Boston University PhD/Ocker Lab/correlations_and_bursts/data/\n",
      "...\n",
      "Done\n",
      "Saving whole unit single trains to:\n",
      "C:/Users/Demogorgon/Documents/College/Marcus/Boston University PhD/Ocker Lab/correlations_and_bursts/data/\n",
      "...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# This cell is the \"work horse.\" All the burst calculations are made here.\n",
    "# The bursts are then sorted by stim presentation ID in the next cell\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "# Cutoff parameter for LogISI\n",
    "CUT_OFF = 0.1\n",
    "\n",
    "# The start and end times for this particular stimulus epoch\n",
    "# (we just want the spikes associated with the stimulus in \"stim\")\n",
    "start_times = list(stim_table[\"start_time\"])\n",
    "start_time = start_times[0]\n",
    "stop_times = list(stim_table[\"stop_time\"])\n",
    "stop_time = stop_times[-1]\n",
    "\n",
    "# Get the start and end times for each stim presentation\n",
    "presentation_start_times = list(stim_table['start_time'])\n",
    "presentation_end_times = list(stim_table['stop_time'])\n",
    "num_presentations = len(stim_presentation_ids)\n",
    "\n",
    "# The entire spike trains of every unit\n",
    "spike_times = session.spike_times\n",
    "\n",
    "burst_calculation_start_time = time.time()\n",
    "unit_update_count = 0\n",
    "num_failed_units = 0\n",
    "unitwise_burst_times = {}\n",
    "unitwise_single_times = {}\n",
    "for unit_id, unit_spikes in spike_times.items():\n",
    "    \n",
    "    # Trim the spike train so that only spikes associated with the stimulus of interest\n",
    "    # are included, assuming one stimulus epoch for that stim type\n",
    "    range_spikes = unit_spikes[(unit_spikes >= start_time)*(unit_spikes <= stop_time)] \n",
    "    try:\n",
    "        #################################################\n",
    "        # First\n",
    "        # Try calculating bursts. For some difficult-to-trace reason, some cells cause\n",
    "        # LogISI and the other burst detection functions to crash. Debugging RPY2 is \n",
    "        # really challenging, so this try-except block should be considdered a kludge\n",
    "        bursts = LogISI(range_spikes, CUT_OFF)\n",
    "\n",
    "        \n",
    "        #################################################\n",
    "        # Second, adjust indicies and add absolute beginning and end times\n",
    "        \n",
    "        # LogISI returns the indices of the first and last spike of every detected burst.\n",
    "        # We need those indices, but we also need the time at which those spikes occured\n",
    "        bursts.rename(columns={'beg':'beg_idx', 'end':'end_idx'}, inplace=True)\n",
    "        bursts['beg_idx'] -= 1\n",
    "        bursts['end_idx'] -= 1\n",
    "        num_bursts = len(bursts)\n",
    "        abs_burst_beg_time = np.zeros(num_bursts)\n",
    "        abs_burst_end_time = np.zeros(num_bursts)\n",
    "        \n",
    "        for k in range(num_bursts):\n",
    "            # bursts.loc[k, 'beg_idx'] -> the index of the time of the \n",
    "            # corresponding spike in range_spikes\n",
    "            # e.g. range_spikes[idx] = 1643.43\n",
    "            # the idx^th spike occurred 1643 seconds after the beginning of\n",
    "            # the session\n",
    "            abs_burst_beg_time[k] = range_spikes[int(bursts.loc[k, 'beg_idx'])]\n",
    "            abs_burst_end_time[k] = range_spikes[int(bursts.loc[k, 'end_idx'])]\n",
    "        \n",
    "        bursts['absolute_beg_time'] = abs_burst_beg_time\n",
    "        bursts['absolute_end_time'] = abs_burst_end_time\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Third, separate bursts from non-bursts (refered to as single spikes or singles)\n",
    "        begginning_indices = bursts[\"beg_idx\"]\n",
    "        ending_indices = bursts[\"end_idx\"]\n",
    "        burst_indices = []\n",
    "        for idx in range(len(begginning_indices)):\n",
    "            burst_index_range = range(int(begginning_indices[idx]), int(ending_indices[idx]+1))\n",
    "            burst_indices += list(burst_index_range)\n",
    "        \n",
    "        # Collect every spike that wasn't counted as a member of a burst\n",
    "        absolute_single_times = [spike_time for idx, spike_time in enumerate(range_spikes) if idx not in burst_indices]\n",
    "        num_singles = len(absolute_single_times)        \n",
    "        singles = pd.DataFrame({\"absolute_spike_time\": absolute_single_times})\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Fourth, associate every burst and every single with a stimulus presentation id\n",
    "        \n",
    "        # burst_associated_presentation = np.zeros(num_bursts)\n",
    "        # for presentation_idx in range(num_presentations):\n",
    "        #     presentation_start_time = presentation_start_times[presentation_idx]\n",
    "        #     presentation_end_time = presentation_end_times[presentation_idx]\n",
    "        #     stim_presentation_id = stim_presentation_ids[presentation_idx]\n",
    "        #     burst_range = bursts.loc[(bursts[\"absolute_beg_time\"] >= presentation_start_time)*(bursts[\"absolute_end_time\"] < presentation_end_time)]\n",
    "            \n",
    "        \n",
    "        burst_associated_presentation = np.zeros(num_bursts)\n",
    "        resume_idx = 0\n",
    "        for time_idx in range(num_bursts):\n",
    "            burst_start_time = abs_burst_beg_time[time_idx]\n",
    "            for presentation_idx in range(resume_idx, num_presentations):\n",
    "                presentation_start_time = presentation_start_times[presentation_idx]\n",
    "                #presentation_end_time = presentation_end_times[presentation_idx]\n",
    "                stim_presentation_id = stim_presentation_ids[presentation_idx]\n",
    "                if burst_start_time >= presentation_start_time:# and burst_start_time < presentation_end_time:\n",
    "                    burst_associated_presentation[time_idx] = stim_presentation_id\n",
    "                else:\n",
    "                    resume_idx = presentation_idx - 1\n",
    "                    break\n",
    "        \n",
    "        bursts[\"stimulus_presentation_id\"] = burst_associated_presentation\n",
    "        \n",
    "        single_associated_presentation = np.zeros(num_singles)\n",
    "        resume_idx = 0\n",
    "        for time_idx in range(num_singles):\n",
    "            single_time = absolute_single_times[time_idx]\n",
    "            for presentation_idx in range(resume_idx, num_presentations):\n",
    "                presentation_start_time = presentation_start_times[presentation_idx]\n",
    "                #presentation_end_time = presentation_end_times[presentation_idx]\n",
    "                stim_presentation_id = stim_presentation_ids[presentation_idx]\n",
    "                if single_time >= presentation_start_time:# and single_time < presentation_end_time:\n",
    "                    single_associated_presentation[time_idx] = stim_presentation_id\n",
    "                else:\n",
    "                    resume_idx = presentation_idx - 1\n",
    "                    break\n",
    "        \n",
    "        singles[\"stimulus_presentation_id\"] = single_associated_presentation\n",
    "        \n",
    "        \n",
    "        #################################################\n",
    "        # Fifth, relativize the burst train and the single train\n",
    "        # \"If the burst start time is less than the stim end time, subtract the start time\n",
    "        # else go to the next start and stop times\"\n",
    "\n",
    "        rel_burst_beg_time = np.zeros(num_bursts)\n",
    "        rel_burst_end_time = np.zeros(num_bursts)\n",
    "        for idx, row in bursts.iterrows():\n",
    "            stim_presentation_id = int(row[\"stimulus_presentation_id\"])\n",
    "            stim_info = stim_table.loc[(stim_table.index==stim_presentation_id)]\n",
    "            stim_beg_time = stim_info[\"start_time\"]\n",
    "            #stim_end_time = stim_info[\"stop_time\"]\n",
    "            rel_burst_beg_time[idx] = row[\"absolute_beg_time\"] - stim_beg_time\n",
    "            rel_burst_end_time[idx] = row[\"absolute_end_time\"] - stim_beg_time\n",
    "            \n",
    "        bursts[\"relative_beg_time\"] = rel_burst_beg_time\n",
    "        bursts[\"relative_end_time\"] = rel_burst_end_time\n",
    "        \n",
    "        rel_single_time = np.zeros(num_singles)\n",
    "        for idx, row in singles.iterrows():\n",
    "            stim_presentation_id = int(row[\"stimulus_presentation_id\"])\n",
    "            stim_info = stim_table.loc[(stim_table.index==stim_presentation_id)]\n",
    "            stim_beg_time = stim_info[\"start_time\"]\n",
    "            rel_single_time[idx] = row[\"absolute_spike_time\"] - stim_beg_time\n",
    "        \n",
    "        singles[\"relative_spike_time\"] = rel_single_time\n",
    "            \n",
    "        \n",
    "        #################################################\n",
    "        # Sixth, store burst and singles     \n",
    "        unitwise_burst_times[unit_id] = bursts\n",
    "        unitwise_single_times[unit_id] = singles\n",
    "        \n",
    "    except AttributeError as e:\n",
    "        # If an exception was caught, log it, store None, and keep going\n",
    "        num_failed_units += 1\n",
    "        unitwise_burst_times[unit_id] = None\n",
    "        unitwise_single_times[unit_id] = None\n",
    "    \n",
    "    # Print an update every 100 cells (sometimes these can take a while, up to an hour on my machine)\n",
    "    unit_update_count += 1\n",
    "    if unit_update_count % 100 == 0:\n",
    "        elapsed_time = time.time() - burst_calculation_start_time\n",
    "        minutes = math.floor(elapsed_time/60)\n",
    "        seconds = math.floor(elapsed_time%60)\n",
    "        print(f\"Time elapsed: {minutes}m {seconds}s. {unit_update_count}/{num_units} burst trains separated from single trains.\")\n",
    "\n",
    "elapsed_time = time.time() - burst_calculation_start_time\n",
    "minutes = math.floor(elapsed_time/60)\n",
    "seconds = math.floor(elapsed_time%60)\n",
    "print(f\"{unit_update_count-num_failed_units}/{num_units} burst trains separated from single trains. Total time elapsed: {minutes}m {seconds}s.\")\n",
    "print(f\"{num_failed_units}/{num_units} separations could not be completed.\")\n",
    "        \n",
    "if SAVE:\n",
    "    print(f\"Saving whole unit burst trains to:\\n{save_path}/\")#{stim}_whole_burst_trains__sesssion_{session_ids[0]}\")\n",
    "    print(\"...\")\n",
    "    with open(f\"{save_path}/{stim}__whole_burst_trains__session_{current_session}.pkl\", 'wb') as f:\n",
    "        pkl.dump(unitwise_burst_times, f)\n",
    "    print(\"Done\")\n",
    "    print(f\"Saving whole unit single trains to:\\n{save_path}/\")\n",
    "    print(\"...\")\n",
    "    with open(f\"{save_path}/{stim}__whole_single_trains__session_{current_session}.pkl\", 'wb') as f:\n",
    "        pkl.dump(unitwise_single_times, f)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Data not saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_count = 0\n",
    "for unit_id, current_unit_bursts in unitwise_burst_times.items():\n",
    "    if current_unit_bursts is not None and (current_unit_bursts < 0).any().any():\n",
    "        negative_count += 1\n",
    "        #print(current_unit_bursts.shape)\n",
    "negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0m 56s. 100/784 burst trains sorted.\n",
      "Time elapsed: 1m 56s. 200/784 burst trains sorted.\n",
      "Time elapsed: 2m 58s. 300/784 burst trains sorted.\n",
      "Time elapsed: 3m 58s. 400/784 burst trains sorted.\n",
      "Time elapsed: 5m 0s. 500/784 burst trains sorted.\n",
      "Time elapsed: 6m 2s. 600/784 burst trains sorted.\n",
      "Time elapsed: 7m 5s. 700/784 burst trains sorted.\n",
      "Saving whole unit burst trains to:\n",
      "C:/Users/Demogorgon/Documents/College/Marcus/Boston University PhD/Ocker Lab/correlations_and_bursts/data/\n",
      "...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# This sorts the whole spike trains by stimulus presentation.\n",
    "\n",
    "# Get relevant times\n",
    "num_presentations = len(stim_presentation_ids)\n",
    "presentation_start_times = list(stim_table['start_time'])\n",
    "presentation_end_times = list(stim_table['stop_time'])\n",
    "\n",
    "# Make variables for reporting time\n",
    "unit_update_count = 0\n",
    "burst_sorting_start_time = time.time()\n",
    "\n",
    "# Start sorting\n",
    "fully_organized_bursts = {}\n",
    "for unit_id in spike_times.keys():\n",
    "    bursts = unitwise_burst_times[unit_id]\n",
    "    \n",
    "    if bursts is not None:\n",
    "        current_unit_presentationwise_bursts = {}\n",
    "        k = 0\n",
    "        for stim_id in stim_presentation_ids:\n",
    "            # Get the start and stop times\n",
    "            current_beg_time = presentation_start_times[k]\n",
    "            current_end_time = presentation_end_times[k]\n",
    "            \n",
    "            # Take out everything that happened before the beginning of this stim\n",
    "            absolute_bursts = bursts.loc[(bursts[\"beg_time\"]>=current_beg_time)]\n",
    "            \n",
    "            # Take out everything that happened after the end of this stim\n",
    "            absolute_bursts = absolute_bursts.loc[(absolute_bursts[\"end_time\"]<=current_end_time)]\n",
    "            \n",
    "            # beg_time and end_time are measured absolutely from the start of the session.\n",
    "            # We also want to know the relative time of the bursts after the particular presentation\n",
    "            relative_starts = absolute_bursts[\"beg_time\"] - current_beg_time\n",
    "            relative_ends = absolute_bursts[\"end_time\"] - current_end_time\n",
    "            \n",
    "            # Name/rename everything appropriately\n",
    "            absolute_bursts.rename(columns={'beg_time':'abs_beg_time', 'end_time':'abs_end_time'}, inplace=True)\n",
    "            absolute_bursts[\"relative_beg_time\"] = relative_starts\n",
    "            absolute_bursts[\"relative_end_time\"] = relative_ends\n",
    "            \n",
    "            # Store and increment\n",
    "            current_unit_presentationwise_bursts[stim_id] = absolute_bursts\n",
    "            k += 1\n",
    "    else:\n",
    "        current_unit_presentationwise_bursts = None\n",
    "    \n",
    "    fully_organized_bursts[unit_id] = current_unit_presentationwise_bursts\n",
    "    \n",
    "    # Print an update every 100 cells (sometimes these can take a while, up to an hour on my machine)\n",
    "    unit_update_count += 1\n",
    "    if unit_update_count % 100 == 0:\n",
    "        elapsed_time = time.time() - burst_sorting_start_time\n",
    "        minutes = math.floor(elapsed_time/60)\n",
    "        seconds = math.floor(elapsed_time%60)\n",
    "        print(f\"Time elapsed: {minutes}m {seconds}s. {unit_update_count}/{num_units} burst trains sorted.\")\n",
    "\n",
    "if SAVE:\n",
    "    print(f\"Saving whole unit burst trains to:\\n{save_path}/\")#{stim}_whole_burst_trains__sesssion_{session_ids[0]}\")\n",
    "    print(\"...\")\n",
    "    with open(f\"{save_path}/{stim}__sorted_burst_trains__session_{session_ids[0]}.pkl\", 'wb') as f:\n",
    "        pkl.dump(fully_organized_bursts, f)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Data not saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3798",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python37\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python37\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3798",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21292\\3109206321.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0munit_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_unit_bursts\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munitwise_burst_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstim_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstim_presentation_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcurrent_unit_bursts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstim_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munit_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python37\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Python37\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3798"
     ]
    }
   ],
   "source": [
    "for unit_id, current_unit_bursts in bursts_by_unit.items():\n",
    "    for stim_id in stim_presentation_ids:\n",
    "        if current_unit_bursts[stim_id] is not None:\n",
    "            print(unit_id)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{save_path}/{stim}_bursts__session_{session_ids[0]}.pkl\", 'rb') as f:\n",
    "    test_load = pkl.load(f)\n",
    "#test_load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
